# Kafka security configuration file
java.security.auth.login.config=/opt/teragrep/cfe_39/etc/config.jaas
# Logger settings
log4j2.configurationFile=/opt/teragrep/cfe_39/etc/log4j2.properties
# What topics are searched from kafka, regex
queueTopicPattern=^testConsumerTopic-*$
# Number of consumers created to the consumer groups
numOfConsumers=2
# Kafka bootstrap servers
bootstrap.servers=test
# Offset, should not be touched
auto.offset.reset=earliest
# Autocommit, should not be touched
enable.auto.commit=false
# Consumer group id, this is to track the progress of reading hte topic
group.id=cfe_39
# Used security protocol and mechanism
security.protocol=SASL_PLAINTEXT
sasl.mechanism=PLAIN
# Maximum records per batch, note that too big number will cause massive load and can cause timeouts to trigger
max.poll.records=500
# How much data can be fetched in one go
fetch.max.bytes=1073741820
# How long for request before timing out. Note that too big max poll records size can cause this to trigger
request.timeout.ms=300000
max.poll.interval.ms=300000
# For testing only
useMockKafkaConsumer=true
# Directory where AVRO files are constructed for HDFS
queueDirectory=/opt/teragrep/cfe_39/etc/AVRO/
# The maximum file size for AVRO-files that are to be stored in HDFS database.
maximumFileSize=3000
# Boolean for deciding if records not in RFC5424 should be skipped or not.
skipNonRFC5424Records=true
# Boolean for deciding if empty RFC5424 records should be skipped or not.
skipEmptyRFC5424Records=true
# HDFS pruning, use 157784760000 value while testing HDFS writes to ensure the test records are not pruned. 157784760000L
pruneOffset=157784760000
# HDFS uri
hdfsuri=hdfs://localhost:45937/
# HDFS path
hdfsPath=hdfs:///opt/teragrep/cfe_39/srv/
# Kerberos
java.security.krb5.kdc=test
java.security.krb5.realm=test
hadoop.security.authentication=test
hadoop.security.authorization=test
dfs.namenode.kerberos.principal.pattern=test
KerberosKeytabUser=test
KerberosKeytabPath=test
dfs.client.use.datanode.hostname=false
kerberosLoginAutorenewal=true
dfs.data.transfer.protection=test
dfs.encrypt.data.transfer.cipher.suites=test
# timeout modifier for when the consumer's cache of intermediate results are flushed to HDFS
consumerTimeout=300000